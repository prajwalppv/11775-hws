{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from joblib import Parallel,delayed\n",
    "# from keras.applications.mobilenet import MobileNet\n",
    "# from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All videos\n",
    "all_videos = open(\"list/all.video\").readlines()\n",
    "all_videos = [i.strip() for i in all_videos]\n",
    "\n",
    "downsampled_videos = \"downsampled_videos\"\n",
    "CNN_FEAT_DIR = \"cnn\"\n",
    "keyframe_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_features_from_video(video_name,model, keyframe_interval):\n",
    "    \"Receives filename of downsampled video and of output path for features. Extracts features in the given keyframe_interval. Saves features in pickled file.\"\n",
    "    # TODO\n",
    "    downsampled_video_filename = os.path.join(downsampled_videos, video_name + '.mp4')\n",
    "    cnn_feat_video_filename = os.path.join(CNN_FEAT_DIR, video_name + '.cnn')\n",
    "    if not os.path.isfile(downsampled_video_filename):\n",
    "            return\n",
    "    frames = get_keyframes(downsampled_video_filename,keyframe_interval)\n",
    "    features = []\n",
    "    max_len = 0\n",
    "    for keyframe in frames:\n",
    "        img_data = image.img_to_array(keyframe)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        feature = model.predict(img_data)\n",
    "        feature = np.array(feature)\n",
    "        features.append(np.reshape(feature.flatten(),(1,-1)))\n",
    "\n",
    "    with open(cnn_feat_video_filename,\"wb\") as o:\n",
    "        pkl.dump(features,o)\n",
    "        \n",
    "\n",
    "def get_keyframes(downsampled_video_filename, keyframe_interval):\n",
    "    \"Generator function which returns the next keyframe.\"\n",
    "\n",
    "    # Create video capture object\n",
    "    video_cap = cv2.VideoCapture(downsampled_video_filename)\n",
    "    frame = 0\n",
    "    while True:\n",
    "        frame += 1\n",
    "        ret, img = video_cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "        if frame % keyframe_interval == 0:\n",
    "            newimg = cv2.resize(img,(224,224))\n",
    "            yield newimg\n",
    "    video_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2935 [00:41<6:26:23,  7.93s/it]/home/ubuntu/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      " 87%|████████▋ | 2548/2935 [10:49:51<1:08:03, 10.55s/it]ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-0eb9538ffbf4>\", line 4, in <module>\n",
      "    res = parallel(delayed(get_cnn_features_from_video)(video,model,keyframe_interval) for video in tqdm(all_videos[:]))\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 934, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 833, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 521, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 427, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "with Parallel(n_jobs=4) as parallel:\n",
    "    \n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    res = parallel(delayed(get_cnn_features_from_video)(video,model,keyframe_interval) for video in tqdm(all_videos[:]))\n",
    "\n",
    "# Without parallel threads\n",
    "# for video in tqdm(all_videos[:]):\n",
    "#     model = VGG16(weights='imagenet', include_top=False)\n",
    "#     get_cnn_features_from_video(video,model,keyframe_interval)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
